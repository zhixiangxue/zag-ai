#!/usr/bin/env python3
"""
Test Free Composition - Verify Order-Independent Splitter Composition

Tests that splitters can be composed in any order and still work correctly.
This verifies the unified interface design where each splitter can process
both Documents and list[BaseUnit].
"""

import sys
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from zag.splitters import MarkdownHeaderSplitter, TextSplitter, RecursiveMergingSplitter
from zag.schemas.markdown import Markdown
from zag.schemas.base import DocumentMetadata


def create_test_doc():
    """Create a test document with varied section sizes"""
    content = """# Section 1
Short content here.

## Subsection 1.1
A bit more content in this subsection with enough text to make it interesting.

# Section 2
This is a much longer section that will definitely exceed our token limits. """ + ("More text. " * 200) + """

## Subsection 2.1
Another subsection with moderate length content.

# Section 3
Short ending section.
"""
    
    metadata = DocumentMetadata(
        source="test",
        source_type="inline",
        file_type="markdown",
        content_length=len(content)
    )
    
    return Markdown(content=content, metadata=metadata)


def analyze_result(name: str, units):
    """Analyze and print results"""
    import tiktoken
    tokenizer = tiktoken.get_encoding("cl100k_base")
    
    tokens = [len(tokenizer.encode(u.content)) for u in units]
    
    print(f"\n{name}:")
    print(f"  Units: {len(units)}")
    print(f"  Token range: {min(tokens)}-{max(tokens)}")
    print(f"  Average: {sum(tokens) // len(tokens)}")
    
    return {
        'count': len(units),
        'min': min(tokens),
        'max': max(tokens),
        'avg': sum(tokens) // len(tokens)
    }


def main():
    print("="*70)
    print("ğŸ§ª Free Composition Test - Order Independence")
    print("="*70)
    
    doc = create_test_doc()
    print(f"\nğŸ“„ Test document created ({len(doc.content)} chars)")
    
    # Test different orderings
    test_cases = [
        ("Order 1: Header â†’ Text â†’ Merge", 
         MarkdownHeaderSplitter() | TextSplitter(1200) | RecursiveMergingSplitter(800)),
        
        ("Order 2: Header â†’ Merge â†’ Text",
         MarkdownHeaderSplitter() | RecursiveMergingSplitter(800) | TextSplitter(1200)),
        
        ("Order 3: Text â†’ Header â†’ Merge",
         TextSplitter(1200) | MarkdownHeaderSplitter() | RecursiveMergingSplitter(800)),
        
        ("Order 4: Text â†’ Merge â†’ Header",
         TextSplitter(1200) | RecursiveMergingSplitter(800) | MarkdownHeaderSplitter()),
        
        ("Order 5: Merge â†’ Header â†’ Text",
         RecursiveMergingSplitter(800) | MarkdownHeaderSplitter() | TextSplitter(1200)),
        
        ("Order 6: Merge â†’ Text â†’ Header",
         RecursiveMergingSplitter(800) | TextSplitter(1200) | MarkdownHeaderSplitter()),
    ]
    
    results = {}
    
    print("\n" + "="*70)
    print("Testing All Possible Orderings...")
    print("="*70)
    
    for name, pipeline in test_cases:
        try:
            units = doc.split(pipeline)
            stats = analyze_result(name, units)
            results[name] = {'success': True, 'stats': stats}
        except Exception as e:
            print(f"\n{name}:")
            print(f"  âŒ FAILED: {str(e)}")
            results[name] = {'success': False, 'error': str(e)}
    
    # Summary
    print("\n" + "="*70)
    print("ğŸ“Š Summary")
    print("="*70)
    
    success_count = sum(1 for r in results.values() if r['success'])
    total_count = len(results)
    
    print(f"\nSuccess Rate: {success_count}/{total_count}")
    
    if success_count == total_count:
        print("\nâœ… ALL ORDERINGS WORK! Free composition verified!")
        
        # Show statistics comparison
        print("\n" + "="*70)
        print("Statistics Comparison")
        print("="*70)
        print(f"{'Order':<40} {'Units':<8} {'Min':<8} {'Max':<8} {'Avg':<8}")
        print("-"*70)
        
        for name, result in results.items():
            if result['success']:
                stats = result['stats']
                short_name = name.split(':')[0]
                print(f"{short_name:<40} {stats['count']:<8} {stats['min']:<8} {stats['max']:<8} {stats['avg']:<8}")
        
        print("\nğŸ’¡ Key Insight:")
        print("   Different orderings produce different results, but all work correctly!")
        print("   Developers can choose the order that best fits their use case.")
    else:
        print("\nâŒ SOME ORDERINGS FAILED:")
        for name, result in results.items():
            if not result['success']:
                print(f"  - {name}: {result['error']}")
    
    # Practical recommendations
    print("\n" + "="*70)
    print("ğŸ¯ Practical Recommendations")
    print("="*70)
    print("""
For typical RAG use cases, recommended orderings:

1. Header â†’ Text â†’ Merge (Standard)
   - Best for: Documents with clear structure
   - Flow: Structure â†’ Size control â†’ Optimization
   
2. Text â†’ Merge â†’ Header (Size-first)
   - Best for: Unstructured documents
   - Flow: Size control â†’ Optimization â†’ Structure extraction
   
3. Merge â†’ Text â†’ Header (Optimization-first)
   - Best for: Pre-split units
   - Flow: Optimization â†’ Size control â†’ Structure refinement
""")


if __name__ == "__main__":
    try:
        import tiktoken
    except ImportError:
        print("âŒ tiktoken is required")
        print("Run: pip install tiktoken")
        sys.exit(1)
    
    main()
