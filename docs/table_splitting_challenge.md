# Table Splitting Challenge: è¡¨æ ¼å¤„ç†çš„å¤šå±‚çº§è®¾è®¡æŒ‘æˆ˜

## é—®é¢˜èƒŒæ™¯

åœ¨åŸºäº Markdown çš„æ–‡æ¡£å¤„ç†ä¸­ï¼ˆç‰¹åˆ«æ˜¯é€šè¿‡ MinerU/Docling è§£æ PDF åç”Ÿæˆçš„ Markdownï¼‰ï¼Œç»å¸¸ä¼šé‡åˆ° **HTML æ ¼å¼çš„è¡¨æ ¼**ï¼ˆå› ä¸º Markdown è¡¨æ ¼ä¸æ”¯æŒ rowspan/colspanï¼‰ã€‚è¿™å¸¦æ¥äº†ä¸€ç³»åˆ—è®¾è®¡æŒ‘æˆ˜ï¼š

1. **Splitter èƒ½å¦æ­£ç¡®åˆ‡åˆ†åŒ…å« HTML è¡¨æ ¼çš„å†…å®¹ï¼Ÿ**
2. **å¦‚ä½•åŒºåˆ† Markdown è¡¨æ ¼å’Œ HTML è¡¨æ ¼ï¼Ÿ**
3. **TableExtractor å¦‚ä½•ç²¾å‡†æ€»ç»“å¤æ‚ HTML è¡¨æ ¼ï¼Ÿ**
4. **å¤æ‚è¡¨æ ¼ä¼šå¼•èµ·å“ªäº›è¿é”ååº”ï¼Ÿ**

---

## æ ¸å¿ƒæŒ‘æˆ˜æ‹†è§£

### 1ï¸âƒ£ MarkdownHeaderSplitter å¯¹ HTML è¡¨æ ¼çš„å¤„ç†èƒ½åŠ›

**å½“å‰å®ç°**: `zag/splitters/markdown/header_based.py`

**èƒ½åŠ›è¯„ä¼°**:
- âœ… æ­£ç¡®å¤„ç† Markdown æ ‡å‡†è¡¨æ ¼ï¼ˆ`| col1 | col2 |`ï¼‰
- âœ… æ­£ç¡®å¤„ç† HTML è¡¨æ ¼å—ï¼ˆä½œä¸ºæ™®é€šæ–‡æœ¬å†…å®¹ä¿ç•™ï¼‰
- âœ… é¿å…åœ¨ä»£ç å—å†…è§£ææ ‡é¢˜
- âŒ **ä¸ä¼šè¯†åˆ«è¡¨æ ¼çš„è¯­ä¹‰è¾¹ç•Œ**ï¼Œåªä¼šæŒ‰æ ‡é¢˜åˆ‡åˆ†

**ç¤ºä¾‹åœºæ™¯**:

```markdown
## äº§å“å¯¹æ¯”

è¿™æ˜¯ä¸€æ®µä»‹ç»æ–‡å­—ã€‚

<table>
  <tr><td>Product</td><td>Price</td></tr>
  <tr><td>A</td><td>100</td></tr>
</table>

è¿™æ˜¯è¡¨æ ¼åçš„æ€»ç»“ã€‚

## ä¸‹ä¸€ç« èŠ‚
...
```

**å½“å‰è¡Œä¸º**: æ•´ä¸ª "äº§å“å¯¹æ¯”" ç« èŠ‚ï¼ˆåŒ…æ‹¬ HTML è¡¨æ ¼ï¼‰ä¼šè¢«åˆ‡åˆ†ä¸º**ä¸€ä¸ª TextUnit**ï¼Œè¡¨æ ¼çš„ HTML ä»£ç ä¼šä¿ç•™åœ¨ `content` ä¸­ã€‚

**é—®é¢˜**: è¡¨æ ¼æ²¡æœ‰è¢«è¯†åˆ«ä¸ºç‹¬ç«‹çš„è¯­ä¹‰å•å…ƒï¼ˆTableUnitï¼‰ï¼Œå½±å“åç»­çš„ï¼š
- å‘é‡æ£€ç´¢æ•ˆæœï¼ˆè¡¨æ ¼å†…å®¹è¢«ç¨€é‡Šåœ¨å¤§æ®µæ–‡æœ¬ä¸­ï¼‰
- å…ƒæ•°æ®æå–ï¼ˆæ— æ³•é’ˆå¯¹è¡¨æ ¼åšç‰¹æ®Šå¤„ç†ï¼‰
- ç»“æ„åŒ–æŸ¥è¯¢ï¼ˆæ— æ³•è¿‡æ»¤è¡¨æ ¼ç±»å‹çš„ Unitï¼‰

---

### 2ï¸âƒ£ å¦‚ä½•åŒºåˆ† Markdown è¡¨æ ¼å’Œ HTML è¡¨æ ¼

#### **æ–¹æ¡ˆ A: åœ¨ Splitter ä¸­å¢å¼ºè¡¨æ ¼è¯†åˆ«**

åˆ›å»ºä¸€ä¸ª `TableAwareSplitter`ï¼Œèƒ½å¤Ÿï¼š

```python
class TableAwareSplitter(BaseSplitter):
    """
    Markdown splitter that recognizes both MD and HTML tables
    
    Logic:
    1. Parse markdown by headers (current logic)
    2. Within each section, detect tables:
       - Markdown tables: | col | col |
       - HTML tables: <table>...</table>
    3. Extract tables as separate TableUnits
    4. Keep text before/after tables as TextUnits
    """
    
    def _detect_tables(self, content: str) -> list[dict]:
        """Detect both MD and HTML tables"""
        tables = []
        
        # Detect HTML tables
        html_pattern = r'<table[^>]*>.*?</table>'
        for match in re.finditer(html_pattern, content, re.DOTALL | re.IGNORECASE):
            tables.append({
                'type': 'html',
                'content': match.group(),
                'start': match.start(),
                'end': match.end()
            })
        
        # Detect Markdown tables (GFM style)
        md_table_pattern = r'(?:^|\n)(\|.+\|(?:\n\|[-:\s|]+\|)(?:\n\|.+\|)*)'
        for match in re.finditer(md_table_pattern, content, re.MULTILINE):
            tables.append({
                'type': 'markdown',
                'content': match.group(1),
                'start': match.start(),
                'end': match.end()
            })
        
        return sorted(tables, key=lambda x: x['start'])
    
    def _do_split(self, document) -> list[BaseUnit]:
        """
        Split markdown with table awareness
        
        1. Detect all tables in content
        2. Split content into segments:
           - Text segments â†’ TextUnit
           - Table segments â†’ TableUnit
        3. Maintain context_path for each unit
        """
        content = document.content
        tables = self._detect_tables(content)
        
        units = []
        last_pos = 0
        
        for table in tables:
            # Add text before table
            if table['start'] > last_pos:
                text_content = content[last_pos:table['start']].strip()
                if text_content:
                    units.append(TextUnit(
                        content=text_content,
                        # ... metadata
                    ))
            
            # Add table unit
            units.append(TableUnit(
                content=table['content'],
                json_data={'table_type': table['type']},
                # ... metadata
            ))
            
            last_pos = table['end']
        
        # Add remaining text
        if last_pos < len(content):
            remaining = content[last_pos:].strip()
            if remaining:
                units.append(TextUnit(content=remaining))
        
        return units
```

**ä¼˜ç‚¹**:
- èƒ½å¤„ç†çº¯ Markdown æ–‡æ¡£ï¼ˆæ²¡æœ‰ç»è¿‡ Reader çš„åœºæ™¯ï¼‰
- ç»Ÿä¸€çš„ Splitter æ¥å£

**ç¼ºç‚¹**:
- æ­£åˆ™è¡¨è¾¾å¼å¯èƒ½ä¸å¤Ÿé²æ£’ï¼ˆåµŒå¥—è¡¨æ ¼ã€è¡¨æ ¼å±æ€§ç­‰ï¼‰
- é‡å¤äº† Reader çš„å·¥ä½œï¼ˆMinerU/Docling å·²ç»è¯†åˆ«è¡¨æ ¼ï¼‰

---

#### **æ–¹æ¡ˆ B: åœ¨ Reader ä¸­ç›´æ¥æ„å»º TableUnitï¼ˆæ¨èï¼‰**

MinerU å’Œ Docling è¿™æ ·çš„ Reader **å·²ç»åšäº†è¡¨æ ¼è¯†åˆ«**ï¼Œå®ƒä»¬çš„è¾“å‡ºä¸­æ˜ç¡®æ ‡æ³¨äº†è¡¨æ ¼ï¼š

**MinerU çš„ content_list è¾“å‡º**:
```python
{
    "type": "table",
    "html": "<table>...</table>",  # â† å·²ç»è¯†åˆ«å‡ºæ¥äº†ï¼
    "latex": "\\begin{tabular}...",
    "page_idx": 2,
    "bbox": [x, y, w, h]
}
```

**Docling çš„è¾“å‡º**:
```python
# DoclingDocument ä¸­çš„ TableItem
table_item = {
    "type": "table",
    "data": {
        "grid": [[cell, cell, ...], ...],
        "num_rows": 5,
        "num_cols": 3
    },
    "prov": [{"bbox": {...}}]
}
```

**æœ€ä¼˜æ–¹æ¡ˆ**: åœ¨ Reader å±‚é¢ï¼ˆå¦‚ `MinerUReader._build_pages_from_content_list`ï¼‰å°±æ„å»º `TableUnit`ï¼š

```python
def _build_pages_from_content_list(self, content_list: list[dict]) -> list[Page]:
    """Build Page objects with TableUnits"""
    
    page_items = {}
    
    for item in content_list:
        page_num = item.get("page_idx", 0) + 1
        
        if page_num not in page_items:
            page_items[page_num] = {
                "units": []  # æ”¹ä¸º units åˆ—è¡¨ï¼Œç»Ÿä¸€å­˜å‚¨
            }
        
        # Classify item type
        item_type = item.get("type", "text")
        
        if item_type == "text":
            # åˆ›å»º TextUnit
            unit = TextUnit(
                unit_id=self.generate_unit_id(),
                content=item.get("text", ""),
                metadata=UnitMetadata(
                    context_path=f"Page{page_num}",
                    custom={
                        "layout_type": item.get("layout_type", "text"),
                        "bbox": item.get("bbox")
                    }
                )
            )
            page_items[page_num]["units"].append(unit)
            
        elif item_type == "table":
            # åˆ›å»º TableUnit
            unit = TableUnit(
                unit_id=self.generate_unit_id(),
                content=item.get("html", ""),  # HTML è¡¨æ ¼
                json_data={
                    "table_type": "html",
                    "raw_html": item.get("html"),
                    "latex": item.get("latex"),  # MinerU è¿˜æä¾› LaTeX
                    "bbox": item.get("bbox"),
                    "page_idx": item.get("page_idx")
                },
                metadata=UnitMetadata(
                    context_path=f"Page{page_num}/Table",
                    custom={"bbox": item.get("bbox")}
                )
            )
            page_items[page_num]["units"].append(unit)
            
        elif item_type in ["image", "figure"]:
            # åˆ›å»º ImageUnit
            unit = ImageUnit(
                unit_id=self.generate_unit_id(),
                content=b"",  # éœ€è¦è¯»å–å›¾ç‰‡äºŒè¿›åˆ¶
                format="png",
                caption=item.get("caption"),
                metadata=UnitMetadata(
                    context_path=f"Page{page_num}/Image",
                    custom={
                        "path": item.get("img_path"),
                        "bbox": item.get("bbox")
                    }
                )
            )
            page_items[page_num]["units"].append(unit)
    
    # Create Page objects
    pages = []
    for page_num in sorted(page_items.keys()):
        units = page_items[page_num]["units"]
        
        # æ„å»º Unit é“¾è¡¨å…³ç³»
        for i in range(len(units)):
            if i > 0:
                units[i].prev_unit_id = units[i - 1].unit_id
            if i < len(units) - 1:
                units[i].next_unit_id = units[i + 1].unit_id
        
        pages.append(Page(
            page_number=page_num,
            content=units,  # ç›´æ¥å­˜å‚¨ Unit åˆ—è¡¨
            metadata={
                "unit_count": len(units)
            }
        ))
    
    return pages
```

**ä¼˜ç‚¹**:
- å¤ç”¨ Reader çš„é«˜ç²¾åº¦è§£æï¼ˆMinerU 82-90+ å‡†ç¡®ç‡ï¼‰
- TableUnit ä¸­åŒ…å«ä¸°å¯Œçš„ç»“æ„åŒ–ä¿¡æ¯ï¼ˆbbox, latex, etc.ï¼‰
- é¿å…é‡å¤è§£æ
- Splitter ä¸éœ€è¦åšè¡¨æ ¼è¯†åˆ«ï¼ˆåªéœ€æŒ‰éœ€åˆ‡åˆ† TextUnitï¼‰

**ç¼ºç‚¹**:
- éœ€è¦ä¿®æ”¹ Reader å®ç°
- Page.content çš„æ•°æ®ç»“æ„éœ€è¦è°ƒæ•´ï¼ˆä» dict æ”¹ä¸º list[BaseUnit]ï¼‰

---

### 3ï¸âƒ£ TableExtractor å¦‚ä½•ç²¾å‡†æ€»ç»“å¤æ‚ HTML è¡¨æ ¼

**å½“å‰å®ç°**: `zag/extractors/table.py`

**å½“å‰ Prompt** (line 58-65):
```python
prompt = f"""ä»¥ä¸‹æ˜¯ä¸€ä¸ªè¡¨æ ¼çš„ç»“æ„åŒ–æ•°æ®ï¼š

{json_data}  # â† è¿™é‡Œæ˜¯ä»€ä¹ˆï¼Ÿ

è¯·ç”¨ 2-3 å¥è¯æ€»ç»“è¿™ä¸ªè¡¨æ ¼çš„å†…å®¹ï¼Œçªå‡ºå…³é”®æ•°æ®å’Œå¯¹æ¯”å…³ç³»ã€‚
"""
```

**é—®é¢˜**:
1. `json_data` çš„æ ¼å¼æ˜¯ä»€ä¹ˆï¼Ÿå¦‚æœæ˜¯ HTML å­—ç¬¦ä¸²ï¼ŒLLM å¯èƒ½ç†è§£ä¸ä½³
2. æ²¡æœ‰è¡¨æ ¼çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€å‰åæ®µè½ï¼‰
3. å¯¹äºå¤æ‚è¡¨æ ¼ï¼ˆå¤šå±‚è¡¨å¤´ã€åˆå¹¶å•å…ƒæ ¼ï¼‰ï¼Œå¯èƒ½ä¸¢å¤±ç»“æ„ä¿¡æ¯

---

#### **æ”¹è¿›æ–¹æ¡ˆ 1: å¢å¼º JSON ç»“æ„**

ä¿®æ”¹ Readerï¼Œè®© `TableUnit.json_data` åŒ…å«ç»“æ„åŒ–ä¿¡æ¯ï¼š

```python
# åœ¨ MinerUReader ä¸­
{
    "table_type": "html",  # or "markdown"
    "raw_html": "<table>...</table>",
    "parsed_structure": {
        "headers": ["Product", "Q1", "Q2", "Q3"],
        "rows": [
            ["ProductA", "100", "120", "130"],
            ["ProductB", "80", "90", "95"]
        ],
        "merged_cells": [
            {"row": 0, "col": 0, "rowspan": 2, "colspan": 1}
        ]
    },
    "context": {
        "preceding_text": "ä¸‹è¡¨å±•ç¤ºäº†å­£åº¦é”€å”®æ•°æ®ï¼š",
        "following_text": "ä»è¡¨æ ¼å¯ä»¥çœ‹å‡ºï¼ŒProductA å¢é•¿æ›´å¿«ã€‚"
    }
}
```

**å¢å¼ºçš„ TableExtractor**:

```python
class TableExtractor(BaseExtractor):
    """Enhanced table extractor with HTML parsing"""
    
    def __init__(self, llm_uri: str, api_key: str):
        self.llm_uri = llm_uri
        self.api_key = api_key
        self._conv = chak.Conversation(llm_uri, api_key=api_key)
    
    async def _extract_from_unit(self, unit) -> Dict:
        if not isinstance(unit, TableUnit):
            return {}
        
        json_data = unit.json_data
        if not json_data:
            return {}
        
        # æ£€æµ‹è¡¨æ ¼ç±»å‹
        table_type = json_data.get("table_type", "unknown")
        
        if table_type == "html":
            # è§£æ HTML è¡¨æ ¼
            parsed = self._parse_html_table(json_data["raw_html"])
            
            # æ„å»ºç»“æ„åŒ– prompt
            prompt = f"""ä»¥ä¸‹æ˜¯ä¸€ä¸ª HTML è¡¨æ ¼çš„ç»“æ„åŒ–æ•°æ®ï¼š

è¡¨å¤´ï¼š{parsed['headers']}
è¡Œæ•°ï¼š{len(parsed['rows'])}
åˆ—æ•°ï¼š{len(parsed['headers'])}
æ•°æ®æ ·ä¾‹ï¼ˆå‰3è¡Œï¼‰ï¼š
{self._format_rows(parsed['rows'][:3])}

ä¸Šä¸‹æ–‡ï¼š
- å‰æ–‡ï¼š{json_data.get('context', {}).get('preceding_text', 'æ— ')}
- åæ–‡ï¼š{json_data.get('context', {}).get('following_text', 'æ— ')}

è¯·ç”¨ 2-3 å¥è¯æ€»ç»“è¿™ä¸ªè¡¨æ ¼çš„å†…å®¹ï¼Œçªå‡ºå…³é”®æ•°æ®å’Œå¯¹æ¯”å…³ç³»ã€‚
è¦æ±‚ï¼šä½¿ç”¨å®Œæ•´çš„å¥å­ï¼Œä¾¿äºå‘é‡æ£€ç´¢ã€‚

æ‘˜è¦ï¼š"""
        else:
            # Markdown æˆ–å…¶ä»–æ ¼å¼
            prompt = f"""ä»¥ä¸‹æ˜¯ä¸€ä¸ªè¡¨æ ¼ï¼š

{unit.content}

è¯·ç”¨ 2-3 å¥è¯æ€»ç»“è¿™ä¸ªè¡¨æ ¼çš„å†…å®¹ã€‚

æ‘˜è¦ï¼š"""
        
        response = await self._conv.asend(prompt)
        return {"table_summary": response.content.strip()}
    
    def _parse_html_table(self, html: str) -> dict:
        """Parse HTML table to structured data"""
        from bs4 import BeautifulSoup
        
        soup = BeautifulSoup(html, 'html.parser')
        table = soup.find('table')
        
        if not table:
            return {"headers": [], "rows": []}
        
        headers = []
        rows = []
        
        # æå–è¡¨å¤´
        thead = table.find('thead')
        if thead:
            header_row = thead.find('tr')
            if header_row:
                headers = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])]
        else:
            # å¦‚æœæ²¡æœ‰ theadï¼Œå°è¯•ç¬¬ä¸€è¡Œ
            first_row = table.find('tr')
            if first_row:
                headers = [th.get_text(strip=True) for th in first_row.find_all(['th', 'td'])]
        
        # æå–æ•°æ®è¡Œ
        tbody = table.find('tbody') or table
        for tr in tbody.find_all('tr')[1 if not thead else 0:]:
            row = [td.get_text(strip=True) for td in tr.find_all(['td', 'th'])]
            if row:
                rows.append(row)
        
        return {
            "headers": headers,
            "rows": rows
        }
    
    def _format_rows(self, rows: list) -> str:
        """Format rows for prompt"""
        return "\n".join([f"  {i+1}. {row}" for i, row in enumerate(rows)])
```

---

#### **æ”¹è¿›æ–¹æ¡ˆ 2: ä½¿ç”¨ VLM ç†è§£è¡¨æ ¼**

å¯¹äºéå¸¸å¤æ‚çš„è¡¨æ ¼ï¼ˆå¦‚è´¢æŠ¥ã€ç§‘æŠ€è®ºæ–‡ä¸­çš„å¯¹æ¯”è¡¨ï¼‰ï¼Œå¯ä»¥ï¼š

```python
class VLMTableExtractor(BaseExtractor):
    """Use VLM to understand complex tables"""
    
    def __init__(self, llm_uri: str, api_key: str, use_vlm: bool = False):
        self.llm_uri = llm_uri
        self.api_key = api_key
        self.use_vlm = use_vlm
        
        if use_vlm:
            # åˆå§‹åŒ– VLMï¼ˆå¦‚ GPT-4o, Qwen-VLï¼‰
            self._vlm = chak.Conversation(
                "bailian/qwen-vl-max",  # æ”¯æŒè§†è§‰çš„æ¨¡å‹
                api_key=api_key
            )
        else:
            self._conv = chak.Conversation(llm_uri, api_key=api_key)
    
    async def _extract_from_unit(self, unit: TableUnit) -> Dict:
        if not isinstance(unit, TableUnit):
            return {}
        
        json_data = unit.json_data
        if not json_data or not self.use_vlm:
            # ä½¿ç”¨å¸¸è§„æ–¹æ³•
            return await self._extract_with_llm(unit)
        
        # Option A: Render HTML to image, use VLM
        if json_data.get('table_type') == 'html':
            # Convert HTML table to image
            table_image = self._render_html_to_image(unit.content)
            
            # Use VLM
            response = await self._vlm.asend(
                "è¿™æ˜¯ä¸€ä¸ªè¡¨æ ¼å›¾ç‰‡ï¼Œè¯·æ€»ç»“å…¶å†…å®¹å’Œå…³é”®ä¿¡æ¯ï¼ˆ2-3å¥è¯ï¼‰ã€‚",
                images=[table_image]
            )
            
            return {"table_summary": response.content.strip()}
        
        # Fallback to text-based
        return await self._extract_with_llm(unit)
    
    def _render_html_to_image(self, html: str) -> bytes:
        """Render HTML table to image using selenium or playwright"""
        from playwright.sync_api import sync_playwright
        
        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page()
            
            # Wrap table in full HTML
            full_html = f"""
            <!DOCTYPE html>
            <html>
            <head>
                <style>
                    table {{ border-collapse: collapse; }}
                    td, th {{ border: 1px solid black; padding: 8px; }}
                </style>
            </head>
            <body>{html}</body>
            </html>
            """
            
            page.set_content(full_html)
            screenshot = page.screenshot()
            browser.close()
            
            return screenshot
```

---

#### **æ”¹è¿›æ–¹æ¡ˆ 3: åˆ†å±‚æ€»ç»“ï¼ˆé€‚åˆè¶…å¤§è¡¨æ ¼ï¼‰**

å¯¹äºå‡ åè¡Œçš„å¤æ‚è¡¨æ ¼ï¼š

```python
class HierarchicalTableExtractor(BaseExtractor):
    """Summarize large tables hierarchically"""
    
    def __init__(self, llm_uri: str, api_key: str, chunk_size: int = 5):
        self.llm_uri = llm_uri
        self.api_key = api_key
        self.chunk_size = chunk_size
        self._conv = chak.Conversation(llm_uri, api_key=api_key)
    
    async def _extract_from_unit(self, unit: TableUnit) -> Dict:
        if not isinstance(unit, TableUnit):
            return {}
        
        json_data = unit.json_data
        if not json_data:
            return {}
        
        # è§£æè¡¨æ ¼
        parsed = self._parse_html_table(json_data.get("raw_html", ""))
        rows = parsed["rows"]
        headers = parsed["headers"]
        
        # å¦‚æœè¡¨æ ¼ä¸å¤§ï¼Œç›´æ¥æ€»ç»“
        if len(rows) <= self.chunk_size:
            return await self._summarize_small_table(headers, rows)
        
        # å¤§è¡¨æ ¼ï¼šåˆ†å±‚æ€»ç»“
        # 1. æ¯ N è¡Œç”Ÿæˆä¸€ä¸ªå°æ‘˜è¦
        row_summaries = []
        for i in range(0, len(rows), self.chunk_size):
            chunk = rows[i:i + self.chunk_size]
            summary = await self._summarize_chunk(headers, chunk, i)
            row_summaries.append(summary)
        
        # 2. æ±‡æ€»æ‰€æœ‰å°æ‘˜è¦
        final_summary = await self._summarize_summaries(headers, row_summaries)
        
        return {"table_summary": final_summary}
    
    async def _summarize_chunk(self, headers: list, rows: list, start_idx: int) -> str:
        """Summarize a chunk of rows"""
        prompt = f"""è¡¨å¤´ï¼š{headers}

æ•°æ®è¡Œ {start_idx+1} åˆ° {start_idx+len(rows)}ï¼š
{self._format_rows(rows)}

ç”¨ä¸€å¥è¯æ€»ç»“è¿™éƒ¨åˆ†æ•°æ®çš„ç‰¹ç‚¹ã€‚

æ‘˜è¦ï¼š"""
        
        response = await self._conv.asend(prompt)
        return response.content.strip()
    
    async def _summarize_summaries(self, headers: list, summaries: list) -> str:
        """Summarize all chunk summaries"""
        prompt = f"""è¿™æ˜¯ä¸€ä¸ªå¤§å‹è¡¨æ ¼çš„åˆ†æ®µæ‘˜è¦ï¼š

è¡¨å¤´ï¼š{headers}

åˆ†æ®µæ‘˜è¦ï¼š
{chr(10).join([f"{i+1}. {s}" for i, s in enumerate(summaries)])}

è¯·ç”¨ 2-3 å¥è¯æ€»ç»“æ•´ä¸ªè¡¨æ ¼çš„å†…å®¹ï¼Œçªå‡ºå…³é”®æ•°æ®å’Œè¶‹åŠ¿ã€‚

æœ€ç»ˆæ‘˜è¦ï¼š"""
        
        response = await self._conv.asend(prompt)
        return response.content.strip()
```

---

### 4ï¸âƒ£ è¿é”ååº”ï¼šå¤æ‚è¡¨æ ¼å¦‚ä½•å½±å“æ•´ä¸ª Pipeline

| **é˜¶æ®µ** | **æ½œåœ¨é—®é¢˜** | **è§£å†³æ–¹æ¡ˆ** |
|---------|-------------|-------------|
| **Reader** | HTML è§£æä¸å‡†ç¡®ã€è¡¨æ ¼è¢«è¯†åˆ«ä¸ºæ–‡æœ¬ | ä½¿ç”¨ MinerU/Docling é«˜ç²¾åº¦è§£æå™¨ï¼›åœ¨ Reader å±‚é¢æ„å»º TableUnit |
| **Splitter** | è¡¨æ ¼è¢«åˆ‡æ–­ã€ä¸ä¸Šä¸‹æ–‡åˆ†ç¦»ã€æ— æ³•è¯†åˆ«è¡¨æ ¼è¾¹ç•Œ | ä½¿ç”¨ TableAwareSplitterï¼›æˆ–ä¾èµ– Reader å·²æ„å»ºçš„ TableUnit |
| **Extractor** | LLM æ— æ³•ç†è§£å¤æ‚ HTMLã€ç¼ºå°‘ä¸Šä¸‹æ–‡ã€è¶…é•¿è¡¨æ ¼ | ä½¿ç”¨ BeautifulSoup è§£æ HTMLï¼›æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼›ä½¿ç”¨ VLM æˆ–åˆ†å±‚æ€»ç»“ |
| **Embedder** | è¡¨æ ¼å‘é‡åŒ–æ•ˆæœå·®ã€è¯­ä¹‰ä¿¡æ¯ä¸è¶³ | ä¾èµ–é«˜è´¨é‡çš„ `table_summary`ï¼›è€ƒè™‘å•ç‹¬ embedding è¡¨æ ¼å’Œæ‘˜è¦ |
| **Retriever** | æ£€ç´¢ä¸åˆ°è¡¨æ ¼å†…å®¹ã€ç»“æ„åŒ–æŸ¥è¯¢å¤±è´¥ | ç¡®ä¿ `table_summary` è´¨é‡ï¼›æ”¯æŒ metadata è¿‡æ»¤ï¼ˆtable_type, page, bboxï¼‰ |
| **Indexer** | è¡¨æ ¼å’Œæ–‡æœ¬æ··åˆç´¢å¼•æ•ˆæœä¸ä½³ | åˆ†åˆ«ç´¢å¼• TextUnit å’Œ TableUnitï¼›æ”¯æŒæŒ‰ unit_type è¿‡æ»¤ |

---

## æ¨èçš„å®Œæ•´è®¾è®¡æ–¹æ¡ˆ

### **Phase 1: Reader å±‚é¢æ”¹é€ ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰**

**ç›®æ ‡**: è®© Reader ç›´æ¥è¾“å‡º TableUnitï¼Œé¿å…åç»­é‡å¤è§£æ

**æ¶‰åŠæ–‡ä»¶**:
- `zag/readers/mineru.py`
- `zag/readers/docling.py`
- `zag/schemas/pdf.py` (Page çš„æ•°æ®ç»“æ„)

**æ”¹åŠ¨ç‚¹**:

1. **ä¿®æ”¹ Page.content çš„æ•°æ®ç»“æ„**:
   ```python
   # å½“å‰: content æ˜¯ dict
   Page(
       page_number=1,
       content={
           "texts": [...],
           "tables": [...],
           "images": [...]
       }
   )
   
   # æ”¹ä¸º: content æ˜¯ list[BaseUnit]
   Page(
       page_number=1,
       content=[
           TextUnit(...),
           TableUnit(...),
           TextUnit(...),
           ImageUnit(...)
       ]
   )
   ```

2. **åœ¨ `_build_pages_from_content_list` ä¸­æ„å»º TableUnit**ï¼ˆè§ä¸Šæ–‡ä»£ç ï¼‰

3. **TableUnit åŒ…å«ä¸°å¯Œçš„ json_data**:
   ```python
   TableUnit(
       content="<table>...</table>",
       json_data={
           "table_type": "html",
           "raw_html": "...",
           "latex": "...",  # MinerU æä¾›
           "bbox": [x, y, w, h],
           "page_idx": 2
       }
   )
   ```

---

### **Phase 2: TableExtractor å¢å¼ºï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰**

**ç›®æ ‡**: è®© TableExtractor èƒ½å¤Ÿå‡†ç¡®æ€»ç»“å¤æ‚ HTML è¡¨æ ¼

**æ¶‰åŠæ–‡ä»¶**:
- `zag/extractors/table.py`

**æ”¹åŠ¨ç‚¹**:

1. æ·»åŠ  `_parse_html_table` æ–¹æ³•ï¼ˆä½¿ç”¨ BeautifulSoupï¼‰
2. æ”¹è¿› Promptï¼ŒåŒ…å«ï¼š
   - ç»“æ„åŒ–çš„è¡¨å¤´å’Œæ•°æ®
   - ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
   - è¡¨æ ¼å¤§å°ï¼ˆè¡Œæ•°ã€åˆ—æ•°ï¼‰
3. å¯é€‰ï¼šæ”¯æŒ VLM æ¨¡å¼
4. å¯é€‰ï¼šæ”¯æŒåˆ†å±‚æ€»ç»“ï¼ˆè¶…å¤§è¡¨æ ¼ï¼‰

---

### **Phase 3: TableAwareSplitterï¼ˆä½ä¼˜å…ˆçº§ï¼Œå¯é€‰ï¼‰**

**ç›®æ ‡**: å¤„ç†çº¯ Markdown æ–‡æ¡£ï¼ˆæ²¡æœ‰ç»è¿‡ Reader çš„åœºæ™¯ï¼‰

**ä½¿ç”¨åœºæ™¯**:
- ç”¨æˆ·ç›´æ¥è¯»å– `.md` æ–‡ä»¶
- Markdown ä¸­åŒ…å« HTML è¡¨æ ¼
- ä¸ä½¿ç”¨ MinerU/Docling Reader

**æ¶‰åŠæ–‡ä»¶**:
- `zag/splitters/markdown/table_aware.py` (æ–°å»º)

---

### **Phase 4: æµ‹è¯•å’ŒéªŒè¯**

**æµ‹è¯•ç”¨ä¾‹**:

1. **ç®€å• HTML è¡¨æ ¼**ï¼ˆ3x3ï¼‰
   - éªŒè¯ï¼šèƒ½æ­£ç¡®è¯†åˆ«å’Œæ€»ç»“
   
2. **å¤æ‚ HTML è¡¨æ ¼**ï¼ˆå¤šå±‚è¡¨å¤´ã€åˆå¹¶å•å…ƒæ ¼ï¼‰
   - éªŒè¯ï¼šèƒ½ä¿ç•™ç»“æ„ä¿¡æ¯
   
3. **è¶…å¤§è¡¨æ ¼**ï¼ˆ50+ è¡Œï¼‰
   - éªŒè¯ï¼šåˆ†å±‚æ€»ç»“ä¸ä¼šè¶…è¿‡ token é™åˆ¶
   
4. **æ··åˆå†…å®¹**ï¼ˆæ–‡æœ¬ + è¡¨æ ¼ + å›¾ç‰‡ï¼‰
   - éªŒè¯ï¼šæ‰€æœ‰ Unit çš„é“¾è¡¨å…³ç³»æ­£ç¡®
   
5. **Markdown æ ‡å‡†è¡¨æ ¼ vs HTML è¡¨æ ¼**
   - éªŒè¯ï¼šä¸¤ç§æ ¼å¼éƒ½èƒ½æ­£ç¡®å¤„ç†

---

## å…³é”®è®¾è®¡å†³ç­–

### âœ… **æ¨èåšæ³•**

1. **åœ¨ Reader å±‚é¢è¯†åˆ«è¡¨æ ¼**ï¼šå¤ç”¨ MinerU/Docling çš„é«˜ç²¾åº¦è§£æ
2. **TableUnit ä¿ç•™å¤šç§æ ¼å¼**ï¼š
   - `content`: åŸå§‹ HTML/Markdown
   - `json_data`: ç»“æ„åŒ–æ•°æ® (headers + rows)
   - `metadata.custom`: bbox, page_idx ç­‰
3. **TableExtractor å…ˆè§£æåæ€»ç»“**ï¼šä½¿ç”¨ BeautifulSoup è§£æ HTMLï¼Œå†äº¤ç»™ LLM
4. **å¯¹äºè¶…å¤æ‚è¡¨æ ¼**ï¼šè€ƒè™‘ä½¿ç”¨ VLM æˆ–åˆ†å±‚æ€»ç»“

### âŒ **é¿å…çš„åšæ³•**

1. **ä¸è¦åœ¨ Splitter ä¸­é‡å¤è§£æè¡¨æ ¼**ï¼ˆReader å·²ç»åšäº†ï¼‰
2. **ä¸è¦ç›´æ¥æŠŠ HTML å­—ç¬¦ä¸²å–‚ç»™ LLM**ï¼ˆéœ€è¦å…ˆç»“æ„åŒ–ï¼‰
3. **ä¸è¦å¿½ç•¥è¡¨æ ¼çš„ä¸Šä¸‹æ–‡**ï¼ˆå‰åæ®µè½ã€æ ‡é¢˜ç­‰ï¼‰
4. **ä¸è¦æŠŠè¡¨æ ¼å’Œå¤§æ®µæ–‡æœ¬æ··åœ¨ä¸€ä¸ª TextUnit ä¸­**ï¼ˆå½±å“æ£€ç´¢ï¼‰

---

## å®ç°è·¯çº¿å›¾

| Phase | ä»»åŠ¡ | ä¼˜å…ˆçº§ | é¢„è®¡å·¥ä½œé‡ |
|-------|------|--------|-----------|
| 1 | ä¿®æ”¹ Reader è¾“å‡º TableUnit | ğŸ”´ é«˜ | 2-3 å°æ—¶ |
| 2 | å¢å¼º TableExtractorï¼ˆHTML è§£æï¼‰ | ğŸŸ¡ ä¸­ | 1-2 å°æ—¶ |
| 3 | æ·»åŠ  VLM æ”¯æŒï¼ˆå¯é€‰ï¼‰ | ğŸŸ¢ ä½ | 2-3 å°æ—¶ |
| 4 | å®ç° TableAwareSplitterï¼ˆå¯é€‰ï¼‰ | ğŸŸ¢ ä½ | 2-3 å°æ—¶ |
| 5 | ç¼–å†™æµ‹è¯•ç”¨ä¾‹ | ğŸŸ¡ ä¸­ | 1 å°æ—¶ |

---

## ç›¸å…³æ–‡ä»¶

**å½“å‰æ¶‰åŠçš„æ–‡ä»¶**:
- `zag/readers/mineru.py` - MinerU Reader
- `zag/readers/docling.py` - Docling Reader
- `zag/splitters/markdown/header_based.py` - Markdown æ ‡é¢˜åˆ‡åˆ†å™¨
- `zag/extractors/table.py` - è¡¨æ ¼æå–å™¨
- `zag/schemas/unit.py` - Unit å®šä¹‰
- `zag/schemas/pdf.py` - PDF å’Œ Page å®šä¹‰

**éœ€è¦æ–°å»ºçš„æ–‡ä»¶**ï¼ˆå¯é€‰ï¼‰:
- `zag/splitters/markdown/table_aware.py` - è¡¨æ ¼æ„ŸçŸ¥åˆ‡åˆ†å™¨
- `zag/extractors/vlm_table.py` - VLM è¡¨æ ¼æå–å™¨

---

## æ€»ç»“

è¿™ä¸ªæŒ‘æˆ˜çš„æ ¸å¿ƒåœ¨äºï¼š**ä¸åŒç»„ä»¶ä¹‹é—´çš„èŒè´£åˆ’åˆ†å’Œæ•°æ®ä¼ é€’**ã€‚

- **Reader**: è´Ÿè´£é«˜ç²¾åº¦è§£æï¼Œè¯†åˆ«è¡¨æ ¼å¹¶æ„å»º TableUnit
- **Splitter**: è´Ÿè´£æŒ‰è¯­ä¹‰åˆ‡åˆ†æ–‡æœ¬ï¼Œä½†ä¸éœ€è¦é‡å¤è§£æè¡¨æ ¼
- **Extractor**: è´Ÿè´£ç†è§£è¡¨æ ¼è¯­ä¹‰ï¼Œç”Ÿæˆé«˜è´¨é‡æ‘˜è¦

é€šè¿‡åœ¨ **Reader å±‚é¢æ„å»º TableUnit**ï¼Œå¯ä»¥æœ€å¤§ç¨‹åº¦é¿å…é‡å¤è§£æï¼ŒåŒæ—¶ä¸ºåç»­çš„ Extractorã€Embedderã€Retriever æä¾›ä¸°å¯Œçš„ç»“æ„åŒ–ä¿¡æ¯ã€‚
